{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fahimul/.conda/envs/CVGL/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/fahimul/.conda/envs/CVGL/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/fahimul/.conda/envs/CVGL/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hyperparameter info:\n",
      "Exp ID: 8402282\n",
      "Embedded dimension: 512\n",
      "Learning rate: 1e-05\n",
      "Batch Size: 64\n",
      "Loss Margin: 1\n",
      "Epoch: 50\n",
      "Training Size: 1526\n",
      "Validation Size: 8884\n",
      "Model Name: CLIP\n",
      "\n",
      "\n",
      "Training Start\n",
      "\n",
      "Date: 2024-06-14 17:58:04.118060\n",
      "\n",
      "Epoch#1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:29<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/50 Loss: 4.150303840637207\n",
      "Epoch#2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 4/24 [00:05<00:28,  1.43s/it]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unable to create tensor, you should probably activate padding with 'padding=True' to have batched tensors with the same length.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/.conda/envs/CVGL/lib/python3.11/site-packages/transformers/feature_extraction_utils.py:182\u001b[0m, in \u001b[0;36mBatchFeature.convert_to_tensors\u001b[0;34m(self, tensor_type)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tensor(value):\n\u001b[0;32m--> 182\u001b[0m     tensor \u001b[38;5;241m=\u001b[39m \u001b[43mas_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;28mself\u001b[39m[key] \u001b[38;5;241m=\u001b[39m tensor\n",
      "File \u001b[0;32m~/.conda/envs/CVGL/lib/python3.11/site-packages/transformers/feature_extraction_utils.py:141\u001b[0m, in \u001b[0;36mBatchFeature._get_is_as_tensor_fns.<locals>.as_tensor\u001b[0;34m(value)\u001b[0m\n\u001b[1;32m    140\u001b[0m     value \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(value)\n\u001b[0;32m--> 141\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 183\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mr1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m) \n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 183\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 145\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    133\u001b[0m save_exp(emb_dim\u001b[38;5;241m=\u001b[39mhypm\u001b[38;5;241m.\u001b[39membed_dim, \n\u001b[1;32m    134\u001b[0m             loss_id\u001b[38;5;241m=\u001b[39mhypm\u001b[38;5;241m.\u001b[39mexpID, \n\u001b[1;32m    135\u001b[0m             ln_rate\u001b[38;5;241m=\u001b[39mhypm\u001b[38;5;241m.\u001b[39mlr, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    141\u001b[0m             mdl_nm\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mmodelName,\n\u001b[1;32m    142\u001b[0m             msg\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mText with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhypm\u001b[38;5;241m.\u001b[39mlang_with\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhypm\u001b[38;5;241m.\u001b[39mlang\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining Start\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 145\u001b[0m all_loses \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhypm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdev\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    146\u001b[0m df_loss \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoss\u001b[39m\u001b[38;5;124m'\u001b[39m: all_loses})\n\u001b[1;32m    147\u001b[0m df_loss\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlosses/losses_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhypm\u001b[38;5;241m.\u001b[39mexpID\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/data/Research/CVGL_Baseline/train.py:80\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, criterion, optimizer, train_loader, num_epochs, dev)\u001b[0m\n\u001b[1;32m     75\u001b[0m running_loss \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     77\u001b[0m \u001b[38;5;66;03m# if(epoch%10==0):\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m#     train_step_eval(step=epoch, mdl=model, dev=dev)\u001b[39;00m\n\u001b[0;32m---> 80\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43manchor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpositive\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnegative\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtxt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m    \u001b[49m\u001b[43manchor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpositive\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnegative\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43manchor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdev\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpositive\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdev\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnegative\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdev\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/CVGL/lib/python3.11/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1182\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[1;32m   1183\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[1;32m   1184\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "File \u001b[0;32m~/.conda/envs/CVGL/lib/python3.11/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.conda/envs/CVGL/lib/python3.11/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.conda/envs/CVGL/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/.conda/envs/CVGL/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/data/Research/CVGL_Baseline/CVUSA_dataset.py:70\u001b[0m, in \u001b[0;36mCVUSA_dataset_cropped.__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform\u001b[38;5;241m!=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;66;03m# anchor_img = self.transform(anchor_img)\u001b[39;00m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;66;03m# positive_img = self.transform(positive_img)                   \u001b[39;00m\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;66;03m# negative_img = self.transform(negative_img)\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     anchor_img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessor(images\u001b[38;5;241m=\u001b[39manchor_img, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 70\u001b[0m     positive_img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpositive_img\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m     negative_img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessor(images\u001b[38;5;241m=\u001b[39mnegative_img, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;66;03m# anchor_text = self.tokenizer(anchor_text, padding=True, return_tensors=\"pt\", max_length=77, truncation=True)\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/CVGL/lib/python3.11/site-packages/transformers/models/clip/processing_clip.py:109\u001b[0m, in \u001b[0;36mCLIPProcessor.__call__\u001b[0;34m(self, text, images, return_tensors, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m     encoding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer(text, return_tensors\u001b[38;5;241m=\u001b[39mreturn_tensors, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtokenizer_kwargs)\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m images \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 109\u001b[0m     image_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_processor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mimage_processor_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m images \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    112\u001b[0m     encoding[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpixel_values\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m image_features\u001b[38;5;241m.\u001b[39mpixel_values\n",
      "File \u001b[0;32m~/.conda/envs/CVGL/lib/python3.11/site-packages/transformers/image_processing_utils.py:551\u001b[0m, in \u001b[0;36mBaseImageProcessor.__call__\u001b[0;34m(self, images, **kwargs)\u001b[0m\n\u001b[1;32m    549\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, images, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BatchFeature:\n\u001b[1;32m    550\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Preprocess an image or a batch of images.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/CVGL/lib/python3.11/site-packages/transformers/models/clip/image_processing_clip.py:346\u001b[0m, in \u001b[0;36mCLIPImageProcessor.preprocess\u001b[0;34m(self, images, do_resize, size, resample, do_center_crop, crop_size, do_rescale, rescale_factor, do_normalize, image_mean, image_std, do_convert_rgb, return_tensors, data_format, input_data_format, **kwargs)\u001b[0m\n\u001b[1;32m    341\u001b[0m images \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    342\u001b[0m     to_channel_dimension_format(image, data_format, input_channel_dim\u001b[38;5;241m=\u001b[39minput_data_format) \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m images\n\u001b[1;32m    343\u001b[0m ]\n\u001b[1;32m    345\u001b[0m data \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpixel_values\u001b[39m\u001b[38;5;124m\"\u001b[39m: images}\n\u001b[0;32m--> 346\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mBatchFeature\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/CVGL/lib/python3.11/site-packages/transformers/feature_extraction_utils.py:78\u001b[0m, in \u001b[0;36mBatchFeature.__init__\u001b[0;34m(self, data, tensor_type)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, Any]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, tensor_type: Union[\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28mstr\u001b[39m, TensorType] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(data)\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_type\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/CVGL/lib/python3.11/site-packages/transformers/feature_extraction_utils.py:188\u001b[0m, in \u001b[0;36mBatchFeature.convert_to_tensors\u001b[0;34m(self, tensor_type)\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moverflowing_values\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    187\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to create tensor returning overflowing values of different lengths. \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 188\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    189\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to create tensor, you should probably activate padding \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    190\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpadding=True\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to have batched tensors with the same length.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    191\u001b[0m         )\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: Unable to create tensor, you should probably activate padding with 'padding=True' to have batched tensors with the same length."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "# from torch.cuda.amp import autocast\n",
    "import numpy as np\n",
    "from CVUSA_dataset import CVUSA_dataset_cropped, CVUSA_Dataset_Eval\n",
    "# from CVUSA_dataset import CVUSA_Dataset_Eval\n",
    "from custom_models import ResNet, VIT, CLIP_model\n",
    "from losses import Contrastive_loss, SoftTripletBiLoss, InfoNCE\n",
    "from train import train\n",
    "from eval import predict, accuracy, calculate_scores\n",
    "import torch.nn.functional as F\n",
    "import copy\n",
    "import math\n",
    "from pytorch_metric_learning import losses as LS\n",
    "from helper_func import get_rand_id, hyparam_info, save_exp, write_to_file\n",
    "from transformers import CLIPProcessor\n",
    "from attributes import Configuration as hypm\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# data_path = '/media/fahimul/2B721C03261BDC8D/Research/datasets/CVUSA' #don't include the / at the end\n",
    "# data_path = '/home/fa947945/datasets/CVUSA_Cropped/CVUSA' #don't include the / at the end\n",
    "data_path = '/data/Research/Dataset/CVUSA_Cropped/CVUSA' #don't include the / at the end\n",
    "\n",
    "# train_data= pd.read_csv(f'{data_path}/splits/train-19zl.csv', header=None)\n",
    "train_data= pd.read_csv(f'{data_path}/splits/train-19zl_5.csv', header=None)\n",
    "# train_data= pd.read_csv(f'{data_path}/splits/train-19zl_30.csv', header=None)\n",
    "\n",
    "val_data= pd.read_csv(f'{data_path}/splits/val-19zl.csv', header=None)\n",
    "\n",
    "# df_loss = pd.DataFrame(columns=['Loss'])\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    # transforms.Resize((224, 224)),\n",
    "    transforms.RandomCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "\n",
    "train_ds = CVUSA_dataset_cropped(df = train_data, path=data_path, transform=transform, train=True, lang=hypm.lang)\n",
    "val_ds = CVUSA_dataset_cropped(df = val_data, path=data_path, transform=transform, train=False, lang=hypm.lang)\n",
    "\n",
    "# val_que = CVUSA_Dataset_Eval(data_folder=data_path, split='val', img_type='query', transforms=transform)\n",
    "# val_ref = CVUSA_Dataset_Eval(data_folder=data_path, split='val', img_type='reference', transforms=transform)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    embed_dim = 512\n",
    "    lr = 0.000001\n",
    "    batch_size = 64\n",
    "    epochs = 100\n",
    "    expID = get_rand_id()\n",
    "    loss_margin = 1\n",
    "\n",
    "    hypm.expID = expID\n",
    "\n",
    "    # torch.cuda.set_device(1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # print(f\"Device: {device}\")\n",
    "\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=hypm.batch_size, shuffle=False)\n",
    "    val_loader = DataLoader(val_ds, batch_size=hypm.batch_size, shuffle=False)\n",
    "    # val_loader_ref = DataLoader(val_ref, batch_size=hypm.batch_size, shuffle=False)\n",
    "\n",
    "    if hypm.save_weights:\n",
    "        os.mkdir(f'model_weights/{hypm.expID}')\n",
    "\n",
    "    # model = ResNet(emb_dim=embed_dim).to(device)\n",
    "    # model_r = ResNet(emb_dim=embed_dim).to(device)\n",
    "    # model_q = ResNet(emb_dim=embed_dim).to(device)\n",
    "\n",
    "    # model = ResNet().to(device)\n",
    "    # model = VIT().to(device)\n",
    "    model = CLIP_model(embed_dim=hypm.embed_dim)\n",
    "\n",
    "    # model = torch.load(f'model_weights/{7355080}/model_tr.pth')\n",
    "\n",
    "    # torch.save(model, f'model_weights/{expID}/model_st.pth')\n",
    "\n",
    "    # criterion = TripletLoss(margin=loss_margin)\n",
    "    # criterion = nn.TripletMarginLoss(margin=0.5)\n",
    "  \n",
    "    # criterion = SoftTripletBiLoss()\n",
    "\n",
    "    loss_fn = torch.nn.CrossEntropyLoss(label_smoothing=hypm.label_smoothing)\n",
    "    criterion = InfoNCE(loss_function=loss_fn,\n",
    "                            device=hypm.device,\n",
    "                            )\n",
    "\n",
    "\n",
    "\n",
    "    parameters = list(filter(lambda p: p.requires_grad, model.parameters()))\n",
    "    # for name, param in model.named_parameters():\n",
    "    #     if param.requires_grad:\n",
    "    #         print(name)\n",
    "    optimizer = optim.Adam(parameters, lr=hypm.lr)\n",
    "    # optimizer = optim.AdamW(parameters, lr=lr)\n",
    "    # optimizer = optim.SGD(parameters, lr=lr)\n",
    "\n",
    "    \n",
    "    \n",
    "    hyparam_info(emb_dim = hypm.embed_dim, \n",
    "                 loss_id = hypm.expID, \n",
    "                 ln_rate = hypm.lr, \n",
    "                 batch = hypm.batch_size, \n",
    "                 epc = hypm.epochs, \n",
    "                 ls_mrgn = hypm.loss_margin, \n",
    "                 trn_sz = train_data.shape[0],\n",
    "                 val_sz= val_data.shape[0],\n",
    "                 mdl_nm = model.modelName)\n",
    "    \n",
    "    save_exp(emb_dim=hypm.embed_dim, \n",
    "                loss_id=hypm.expID, \n",
    "                ln_rate=hypm.lr, \n",
    "                batch=hypm.batch_size, \n",
    "                epc=hypm.epochs, \n",
    "                ls_mrgn=hypm.loss_margin, \n",
    "                trn_sz=train_data.shape[0],\n",
    "                val_sz= val_data.shape[0],\n",
    "                mdl_nm=model.modelName,\n",
    "                msg=f'Text with {hypm.lang_with} {hypm.lang}')\n",
    "\n",
    "    print(\"Training Start\")\n",
    "    all_loses = train(model, criterion, optimizer, train_loader, num_epochs=hypm.epochs, dev=device)\n",
    "    df_loss = pd.DataFrame({'Loss': all_loses})\n",
    "    df_loss.to_csv(f'losses/losses_{hypm.expID}.csv')\n",
    "\n",
    "    write_to_file(expID=hypm.expID, msg=f'End of training: ', content=datetime.now())\n",
    "\n",
    "\n",
    "    print(\"\\nExtract Features:\")\n",
    "    query_features, reference_features, labels = predict(model=model, dataloader=val_loader, dev=device, isQuery=True)\n",
    "    # reference_features, reference_labels = predict(model = model, dataloader=val_loader_ref, dev=device, isQuery=False) \n",
    "    \n",
    "\n",
    "\n",
    "    print(\"Compute Scores:\")\n",
    "    # r1 =  calculate_scores(query_features, reference_features, query_labels, reference_labels, step_size=1000, ranks=[1, 5, 10])\n",
    "    r1 =  accuracy(query_features=query_features, reference_features=reference_features, query_labels=labels, topk=[1, 5, 10])\n",
    "\n",
    "    write_to_file(expID=hypm.expID, msg=f'Final eval: ', content=r1)\n",
    "\n",
    "\n",
    "    if hypm.save_weights:\n",
    "        torch.save(model, f'model_weights/{hypm.expID}/model_tr.pth')\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    print(f'{r1}\\n') \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "# from torch.cuda.amp import autocast\n",
    "import numpy as np\n",
    "from CVUSA_dataset import CVUSA_dataset_cropped, CVUSA_Dataset_Eval\n",
    "# from CVUSA_dataset import CVUSA_Dataset_Eval\n",
    "from custom_models import ResNet, VIT, CLIP_model\n",
    "from losses import Contrastive_loss, SoftTripletBiLoss, InfoNCE\n",
    "from train import train\n",
    "from eval import predict, accuracy, calculate_scores\n",
    "import torch.nn.functional as F\n",
    "import copy\n",
    "import math\n",
    "from pytorch_metric_learning import losses as LS\n",
    "from helper_func import get_rand_id, hyparam_info, save_losses\n",
    "from transformers import CLIPProcessor\n",
    "from attributes import Configuration as hypm\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# data_path = '/media/fahimul/2B721C03261BDC8D/Research/datasets/CVUSA' #don't include the / at the end\n",
    "# data_path = '/home/fa947945/datasets/CVUSA_Cropped/CVUSA' #don't include the / at the end\n",
    "data_path = '/data/Research/Dataset/CVUSA_Cropped/CVUSA' #don't include the / at the end\n",
    "\n",
    "# train_data= pd.read_csv(f'{data_path}/splits/train-19zl.csv', header=None)\n",
    "train_data= pd.read_csv(f'{data_path}/splits/train-19zl_30.csv', header=None)\n",
    "val_data= pd.read_csv(f'{data_path}/splits/val-19zl.csv', header=None)\n",
    "\n",
    "# df_loss = pd.DataFrame(columns=['Loss'])\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    # transforms.Resize((224, 224)),\n",
    "    transforms.RandomCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "\n",
    "train_ds = CVUSA_dataset_cropped(df = train_data, path=data_path, transform=transform)\n",
    "val_ds = CVUSA_dataset_cropped(df = val_data, path=data_path, transform=transform)\n",
    "\n",
    "# val_que = CVUSA_Dataset_Eval(data_folder=data_path, split='val', img_type='query', transforms=transform)\n",
    "# val_ref = CVUSA_Dataset_Eval(data_folder=data_path, split='val', img_type='reference', transforms=transform)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Device: {device}\")\n",
    "    embed_dim = 512\n",
    "    lr = 0.00001\n",
    "    batch_size = 64\n",
    "    epochs = 100\n",
    "    expID = get_rand_id()\n",
    "    loss_margin = 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=hypm.batch_size, shuffle=False)\n",
    "    val_loader = DataLoader(val_ds, batch_size=hypm.batch_size, shuffle=False)\n",
    "    # val_loader_ref = DataLoader(val_ref, batch_size=hypm.batch_size, shuffle=False)\n",
    "\n",
    "    if hypm.save_weights:\n",
    "        os.mkdir(f'model_weights/{hypm.expID}')\n",
    "\n",
    "    # model = ResNet(emb_dim=embed_dim).to(device)\n",
    "    # model_r = ResNet(emb_dim=embed_dim).to(device)\n",
    "    # model_q = ResNet(emb_dim=embed_dim).to(device)\n",
    "\n",
    "    # model = ResNet().to(device)\n",
    "    # model = VIT().to(device)\n",
    "    model = CLIP_model(embed_dim=hypm.embed_dim)\n",
    "    \n",
    "    # torch.save(model, f'model_weights/{expID}/model_st.pth')\n",
    "\n",
    "    # criterion = TripletLoss(margin=loss_margin)\n",
    "    # criterion = nn.TripletMarginLoss(margin=0.5)\n",
    "  \n",
    "    # criterion = SoftTripletBiLoss()\n",
    "\n",
    "    loss_fn = torch.nn.CrossEntropyLoss(label_smoothing=hypm.label_smoothing)\n",
    "    criterion = InfoNCE(loss_function=loss_fn,\n",
    "                            device=device,\n",
    "                            )\n",
    "\n",
    "\n",
    "\n",
    "    parameters = list(filter(lambda p: p.requires_grad, model.parameters()))\n",
    "    # for name, param in model.named_parameters():\n",
    "    #     if param.requires_grad:\n",
    "    #         print(name)\n",
    "    optimizer = optim.Adam(parameters, lr=hypm.lr)\n",
    "    # optimizer = optim.AdamW(parameters, lr=lr)\n",
    "    # optimizer = optim.SGD(parameters, lr=lr)\n",
    "\n",
    "    \n",
    "    \n",
    "    hyparam_info(emb_dim = hypm.embed_dim, \n",
    "                 loss_id = hypm.expID, \n",
    "                 ln_rate = hypm.lr, \n",
    "                 batch = hypm.batch_size, \n",
    "                 epc = hypm.epochs, \n",
    "                 ls_mrgn = hypm.loss_margin, \n",
    "                 trn_sz = train_data.shape[0], \n",
    "                 mdl_nm = model.modelName)\n",
    "\n",
    "    print(\"Training Start\")\n",
    "    all_loses = train(model, criterion, optimizer, train_loader, num_epochs=hypm.epochs, dev=device)\n",
    "    df_loss = pd.DataFrame({'Loss': all_loses})\n",
    "    df_loss.to_csv(f'losses/losses_{expID}.csv')\n",
    "\n",
    "\n",
    "\n",
    "    print(\"\\nExtract Features:\")\n",
    "    query_features, reference_features, labels = predict(model=model, dataloader=val_loader, dev=device, isQuery=True)\n",
    "    # reference_features, reference_labels = predict(model = model, dataloader=val_loader_ref, dev=device, isQuery=False) \n",
    "    \n",
    "\n",
    "\n",
    "    print(\"Compute Scores:\")\n",
    "    # r1 =  calculate_scores(query_features, reference_features, query_labels, reference_labels, step_size=1000, ranks=[1, 5, 10])\n",
    "    r1 =  accuracy(query_features=query_features, reference_features=reference_features, query_labels=labels, topk=[1, 5, 10])\n",
    "    \n",
    "    save_losses(df=df_loss, \n",
    "                emb_dim=embed_dim, \n",
    "                loss_id=expID, \n",
    "                ln_rate=lr, \n",
    "                batch=batch_size, \n",
    "                epc=epochs, \n",
    "                ls_mrgn=loss_margin, \n",
    "                trn_sz=train_data.shape[0],\n",
    "                mdl_nm=model.modelName,\n",
    "                rslt=r1)\n",
    "\n",
    "\n",
    "    print(r1) \n",
    "        \n",
    "    if hypm.save_weights:\n",
    "        torch.save(model, f'model_weights/{hypm.expID}/model_tr.pth')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "# from torch.cuda.amp import autocast\n",
    "import numpy as np\n",
    "from CVUSA_dataset import CVUSA_dataset_cropped, CVUSA_Dataset_Eval\n",
    "# from CVUSA_dataset import CVUSA_Dataset_Eval\n",
    "from custom_models import ResNet, VIT, CLIP_model\n",
    "from losses import SoftTripletBiLoss, InfoNCE\n",
    "from train import train\n",
    "from eval import predict, accuracy, calculate_scores\n",
    "import torch.nn.functional as F\n",
    "import copy\n",
    "import math\n",
    "from pytorch_metric_learning import losses as LS\n",
    "from helper_func import get_rand_id, hyparam_info, save_losses\n",
    "from transformers import CLIPProcessor\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# data_path = '/media/fahimul/2B721C03261BDC8D/Research/datasets/CVUSA' #don't include the / at the end\n",
    "# data_path = '/home/fa947945/datasets/CVUSA_Cropped/CVUSA' #don't include the / at the end\n",
    "data_path = '/data/Research/Dataset/CVUSA_Cropped/CVUSA' #don't include the / at the end\n",
    "\n",
    "train_data= pd.read_csv(f'{data_path}/splits/train-19zl.csv')\n",
    "val_data= pd.read_csv(f'{data_path}/splits/val-19zl.csv')\n",
    "\n",
    "# df_loss = pd.DataFrame(columns=['Loss'])\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    # transforms.RandomCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "# transform = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "\n",
    "\n",
    "train_ds = CVUSA_dataset_cropped(df = train_data, path=data_path, transform=transform)\n",
    "val_que = CVUSA_Dataset_Eval(data_folder=data_path, split='train', img_type='query', transforms=transform)\n",
    "val_ref = CVUSA_Dataset_Eval(data_folder=data_path, split='train', img_type='reference', transforms=transform)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Device: {device}\")\n",
    "    embed_dim = 1000\n",
    "    lr = 0.005\n",
    "    batch_size = 64\n",
    "    epochs = 50\n",
    "    expID = get_rand_id()\n",
    "    loss_margin = 1\n",
    "\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=False)\n",
    "    val_loader_que = DataLoader(val_que, batch_size=batch_size, shuffle=False)\n",
    "    val_loader_ref = DataLoader(val_ref, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # model = ResNet(emb_dim=embed_dim).to(device)\n",
    "    # model_r = ResNet(emb_dim=embed_dim).to(device)\n",
    "    # model_q = ResNet(emb_dim=embed_dim).to(device)\n",
    "\n",
    "    # model = ResNet()\n",
    "    # model = VIT().to(device)\n",
    "    model = CLIP_model(embed_dim=embed_dim)\n",
    "    \n",
    "    # torch.save(model, f'model_weights/model_st.pth')\n",
    "\n",
    "    # criterion = TripletLoss(margin=loss_margin)\n",
    "    # criterion = nn.TripletMarginLoss(margin=0.5)\n",
    "  \n",
    "    # criterion = SoftTripletBiLoss()\n",
    "\n",
    "    loss_fn = torch.nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "    criterion = InfoNCE(loss_function=loss_fn,\n",
    "                            device=device,\n",
    "                            )\n",
    "\n",
    "\n",
    "    parameters = list(filter(lambda p: p.requires_grad, model.parameters()))\n",
    "    # for name, param in model.named_parameters():\n",
    "    #     if param.requires_grad:\n",
    "    #         print(name)\n",
    "    optimizer = optim.Adam(parameters, lr=lr)\n",
    "    # optimizer = optim.AdamW(parameters, lr=lr)\n",
    "    # optimizer = optim.SGD(parameters, lr=lr)\n",
    "\n",
    "    \n",
    "    \n",
    "    hyparam_info(emb_dim=embed_dim, loss_id=expID, ln_rate=lr, batch=batch_size, epc=epochs, ls_mrgn=loss_margin, trn_sz=train_data.shape[0], mdl_nm=model.modelName)\n",
    "\n",
    "    print(\"Training Start\")\n",
    "    all_loses = train(model, criterion, optimizer, train_loader, num_epochs=epochs, dev=device)\n",
    "    df_loss = pd.DataFrame({'Loss': all_loses})\n",
    "    df_loss.to_csv(f'losses/losses_{expID}.csv')\n",
    "\n",
    "\n",
    "\n",
    "    print(\"\\nExtract Features:\")\n",
    "    query_features, query_labels = predict(model=model, dataloader=val_loader_que, dev=device, isQuery=True)\n",
    "    reference_features, reference_labels = predict(model = model, dataloader=val_loader_ref, dev=device, isQuery=False) \n",
    "    \n",
    "\n",
    "\n",
    "    print(\"Compute Scores:\")\n",
    "    # r1 =  calculate_scores(query_features, reference_features, query_labels, reference_labels, step_size=1000, ranks=[1, 5, 10])\n",
    "    r1 =  accuracy(query_features=query_features, reference_features=reference_features, query_labels=query_labels, topk=[1, 5, 10])\n",
    "    \n",
    "    save_losses(df=df_loss, \n",
    "                emb_dim=embed_dim, \n",
    "                loss_id=expID, \n",
    "                ln_rate=lr, \n",
    "                batch=batch_size, \n",
    "                epc=epochs, \n",
    "                ls_mrgn=loss_margin, \n",
    "                trn_sz=train_data.shape[0],\n",
    "                mdl_nm=model.modelName,\n",
    "                rslt=r1)\n",
    "\n",
    "\n",
    "    print(r1) \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fahimul/.conda/envs/CVGL/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/fahimul/.conda/envs/CVGL/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/fahimul/.conda/envs/CVGL/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fahimul/.conda/envs/CVGL/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/fahimul/.conda/envs/CVGL/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hyperparameter info:\n",
      "Exp ID: 6866346\n",
      "Embedded dimension: 1000\n",
      "Learning rate: 1e-05\n",
      "Batch Size: 64\n",
      "Loss Margin: 1\n",
      "Epoch: 100\n",
      "Training Size: 10658\n",
      "Model Name: CLIP\n",
      "\n",
      "\n",
      "Training Start\n",
      "\n",
      "Date: 2024-05-27 23:19:06.938859\n",
      "\n",
      "Epoch#0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:26<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/100 Loss: 3.67783522605896\n",
      "Epoch#1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:24<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2/100 Loss: 3.4610238075256348\n",
      "Epoch#2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:24<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3/100 Loss: 3.390040874481201\n",
      "Epoch#3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:25<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4/100 Loss: 3.353699207305908\n",
      "Epoch#4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:23<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5/100 Loss: 3.3104639053344727\n",
      "Epoch#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:23<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6/100 Loss: 3.2868146896362305\n",
      "Epoch#6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:24<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7/100 Loss: 3.261460065841675\n",
      "Epoch#7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:24<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8/100 Loss: 3.2388217449188232\n",
      "Epoch#8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:24<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9/100 Loss: 3.2311360836029053\n",
      "Epoch#9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:23<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10/100 Loss: 3.208472728729248\n",
      "Epoch#10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:24<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11/100 Loss: 3.1945183277130127\n",
      "Epoch#11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:24<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12/100 Loss: 3.1947290897369385\n",
      "Epoch#12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:25<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13/100 Loss: 3.1859302520751953\n",
      "Epoch#13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:24<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14/100 Loss: 3.178889751434326\n",
      "Epoch#14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:24<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15/100 Loss: 3.170306444168091\n",
      "Epoch#15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:25<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16/100 Loss: 3.164330005645752\n",
      "Epoch#16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:24<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17/100 Loss: 3.1545979976654053\n",
      "Epoch#17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:24<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18/100 Loss: 3.146165609359741\n",
      "Epoch#18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:24<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19/100 Loss: 3.1381149291992188\n",
      "Epoch#19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:24<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20/100 Loss: 3.130805253982544\n",
      "Epoch#20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:24<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21/100 Loss: 3.12326979637146\n",
      "Epoch#21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:24<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22/100 Loss: 3.1190996170043945\n",
      "Epoch#22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:24<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23/100 Loss: 3.1181888580322266\n",
      "Epoch#23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:23<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24/100 Loss: 3.116948366165161\n",
      "Epoch#24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:24<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25/100 Loss: 3.1094067096710205\n",
      "Epoch#25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:25<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26/100 Loss: 3.1017422676086426\n",
      "Epoch#26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:24<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27/100 Loss: 3.097783088684082\n",
      "Epoch#27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:24<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28/100 Loss: 3.094224452972412\n",
      "Epoch#28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:24<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29/100 Loss: 3.089644193649292\n",
      "Epoch#29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:25<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30/100 Loss: 3.084209442138672\n",
      "Epoch#30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:23<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 31/100 Loss: 3.079519748687744\n",
      "Epoch#31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:24<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 32/100 Loss: 3.0773210525512695\n",
      "Epoch#32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:25<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 33/100 Loss: 3.0771524906158447\n",
      "Epoch#33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:25<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 34/100 Loss: 3.0760586261749268\n",
      "Epoch#34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:25<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 35/100 Loss: 3.0722129344940186\n",
      "Epoch#35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:24<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 36/100 Loss: 3.068732261657715\n",
      "Epoch#36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:24<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 37/100 Loss: 3.06258487701416\n",
      "Epoch#37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:25<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 38/100 Loss: 3.058687210083008\n",
      "Epoch#38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:26<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 39/100 Loss: 3.055567979812622\n",
      "Epoch#39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:25<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40/100 Loss: 3.053041458129883\n",
      "Epoch#40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:24<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 41/100 Loss: 3.052685260772705\n",
      "Epoch#41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:25<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 42/100 Loss: 3.054924249649048\n",
      "Epoch#42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:25<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 43/100 Loss: 3.0530338287353516\n",
      "Epoch#43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:25<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 44/100 Loss: 3.0506651401519775\n",
      "Epoch#44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:24<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 45/100 Loss: 3.0471460819244385\n",
      "Epoch#45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:27<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 46/100 Loss: 3.042741060256958\n",
      "Epoch#46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:24<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 47/100 Loss: 3.037795305252075\n",
      "Epoch#47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:26<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 48/100 Loss: 3.0342514514923096\n",
      "Epoch#48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:24<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 49/100 Loss: 3.0324153900146484\n",
      "Epoch#49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:25<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 50/100 Loss: 3.0312507152557373\n",
      "Epoch#50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:25<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 51/100 Loss: 3.031346082687378\n",
      "Epoch#51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:24<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 52/100 Loss: 3.031572103500366\n",
      "Epoch#52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:25<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 53/100 Loss: 3.0308678150177\n",
      "Epoch#53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:25<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 54/100 Loss: 3.02876615524292\n",
      "Epoch#54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:25<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 55/100 Loss: 3.028168201446533\n",
      "Epoch#55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:25<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 56/100 Loss: 3.0268430709838867\n",
      "Epoch#56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:27<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 57/100 Loss: 3.023682117462158\n",
      "Epoch#57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:26<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 58/100 Loss: 3.0221352577209473\n",
      "Epoch#58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:24<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 59/100 Loss: 3.01987886428833\n",
      "Epoch#59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:25<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 60/100 Loss: 3.0188169479370117\n",
      "Epoch#60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:24<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 61/100 Loss: 3.0181427001953125\n",
      "Epoch#61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:24<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 62/100 Loss: 3.0171589851379395\n",
      "Epoch#62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:24<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 63/100 Loss: 3.01503849029541\n",
      "Epoch#63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:24<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 64/100 Loss: 3.0125269889831543\n",
      "Epoch#64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:25<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 65/100 Loss: 3.011002779006958\n",
      "Epoch#65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:23<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 66/100 Loss: 3.0106594562530518\n",
      "Epoch#66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:25<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 67/100 Loss: 3.0104265213012695\n",
      "Epoch#67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:25<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 68/100 Loss: 3.010394811630249\n",
      "Epoch#68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:25<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 69/100 Loss: 3.0106945037841797\n",
      "Epoch#69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:24<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 70/100 Loss: 3.011859893798828\n",
      "Epoch#70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:24<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 71/100 Loss: 3.039456605911255\n",
      "Epoch#71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:25<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 72/100 Loss: 3.0525519847869873\n",
      "Epoch#72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:24<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 73/100 Loss: 3.032297372817993\n",
      "Epoch#73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:25<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 74/100 Loss: 3.009859561920166\n",
      "Epoch#74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:24<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 75/100 Loss: 3.0010905265808105\n",
      "Epoch#75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:25<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 76/100 Loss: 2.997390031814575\n",
      "Epoch#76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:25<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 77/100 Loss: 2.9954235553741455\n",
      "Epoch#77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:24<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 78/100 Loss: 2.994933605194092\n",
      "Epoch#78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:25<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 79/100 Loss: 2.99466609954834\n",
      "Epoch#79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:24<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 80/100 Loss: 2.9944465160369873\n",
      "Epoch#80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:24<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 81/100 Loss: 2.994993209838867\n",
      "Epoch#81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:25<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 82/100 Loss: 2.9961740970611572\n",
      "Epoch#82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:26<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 83/100 Loss: 2.9975948333740234\n",
      "Epoch#83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:26<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 84/100 Loss: 2.999452590942383\n",
      "Epoch#84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:24<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 85/100 Loss: 3.0016772747039795\n",
      "Epoch#85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:25<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 86/100 Loss: 3.0031633377075195\n",
      "Epoch#86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:24<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 87/100 Loss: 3.003349542617798\n",
      "Epoch#87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:24<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 88/100 Loss: 3.0017383098602295\n",
      "Epoch#88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:24<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 89/100 Loss: 2.999363422393799\n",
      "Epoch#89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:24<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 90/100 Loss: 2.9977176189422607\n",
      "Epoch#90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:24<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 91/100 Loss: 3.0091552734375\n",
      "Epoch#91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:23<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 92/100 Loss: 3.0385544300079346\n",
      "Epoch#92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:24<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 93/100 Loss: 3.0350849628448486\n",
      "Epoch#93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:23<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 94/100 Loss: 3.0056509971618652\n",
      "Epoch#94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:24<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 95/100 Loss: 2.9953083992004395\n",
      "Epoch#95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:25<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 96/100 Loss: 2.9920146465301514\n",
      "Epoch#96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:24<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 97/100 Loss: 2.9905757904052734\n",
      "Epoch#97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:25<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 98/100 Loss: 2.989732503890991\n",
      "Epoch#98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:24<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 99/100 Loss: 2.989344596862793\n",
      "Epoch#99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:24<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100/100 Loss: 2.9894866943359375\n",
      "\n",
      "Date: 2024-05-28 05:00:32.640961\n",
      "\n",
      "\n",
      "Extract Features:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 139/139 [00:15<00:00,  9.04it/s]\n",
      "100%|██████████| 139/139 [01:02<00:00,  2.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute Scores:\n",
      "Percentage-top1:1.2269248086447546, top5:4.209815398469158, top10:7.080144079243585, top1%:30.08779828905898, time:0.19346070289611816\n",
      "[ 1.22692481  4.2098154   7.08014408 30.08779829]\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "# from torch.cuda.amp import autocast\n",
    "import numpy as np\n",
    "from CVUSA_dataset import CVUSA_dataset_cropped, CVUSA_Dataset_Eval\n",
    "# from CVUSA_dataset import CVUSA_Dataset_Eval\n",
    "from custom_models import ResNet, VIT, CLIP_model\n",
    "from losses import Contrastive_loss, SoftTripletBiLoss, InfoNCE\n",
    "from train import train\n",
    "from eval import predict, accuracy, calculate_scores\n",
    "import torch.nn.functional as F\n",
    "import copy\n",
    "import math\n",
    "from pytorch_metric_learning import losses as LS\n",
    "from helper_func import get_rand_id, hyparam_info, save_losses\n",
    "from transformers import CLIPProcessor\n",
    "from attributes import Configuration\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# data_path = '/media/fahimul/2B721C03261BDC8D/Research/datasets/CVUSA' #don't include the / at the end\n",
    "# data_path = '/home/fa947945/datasets/CVUSA_Cropped/CVUSA' #don't include the / at the end\n",
    "data_path = '/data/Research/Dataset/CVUSA_Cropped/CVUSA' #don't include the / at the end\n",
    "\n",
    "# train_data= pd.read_csv(f'{data_path}/splits/train-19zl.csv')\n",
    "train_data= pd.read_csv(f'{data_path}/splits/train-19zl_30.csv')\n",
    "val_data= pd.read_csv(f'{data_path}/splits/val-19zl.csv')\n",
    "\n",
    "# df_loss = pd.DataFrame(columns=['Loss'])\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    # transforms.Resize((224, 224)),\n",
    "    transforms.RandomCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "\n",
    "train_ds = CVUSA_dataset_cropped(df = train_data, path=data_path, transform=transform)\n",
    "val_que = CVUSA_Dataset_Eval(data_folder=data_path, split='val', img_type='query', transforms=transform)\n",
    "val_ref = CVUSA_Dataset_Eval(data_folder=data_path, split='val', img_type='reference', transforms=transform)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Device: {device}\")\n",
    "    embed_dim = 1000\n",
    "    lr = 0.00001\n",
    "    batch_size = 64\n",
    "    epochs = 100\n",
    "    expID = get_rand_id()\n",
    "    loss_margin = 1\n",
    "\n",
    "\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=False)\n",
    "    val_loader_que = DataLoader(val_que, batch_size=batch_size, shuffle=False)\n",
    "    val_loader_ref = DataLoader(val_ref, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    os.mkdir(f'model_weights/{expID}')\n",
    "\n",
    "    # model = ResNet(emb_dim=embed_dim).to(device)\n",
    "    # model_r = ResNet(emb_dim=embed_dim).to(device)\n",
    "    # model_q = ResNet(emb_dim=embed_dim).to(device)\n",
    "\n",
    "    # model = ResNet().to(device)\n",
    "    # model = VIT().to(device)\n",
    "    model = CLIP_model(embed_dim=embed_dim)\n",
    "    \n",
    "    # torch.save(model, f'model_weights/{expID}/model_st.pth')\n",
    "\n",
    "    # criterion = TripletLoss(margin=loss_margin)\n",
    "    # criterion = nn.TripletMarginLoss(margin=0.5)\n",
    "  \n",
    "    # criterion = SoftTripletBiLoss()\n",
    "\n",
    "    loss_fn = torch.nn.CrossEntropyLoss(label_smoothing=0.5)\n",
    "    criterion = InfoNCE(loss_function=loss_fn,\n",
    "                            device=device,\n",
    "                            )\n",
    "\n",
    "\n",
    "\n",
    "    parameters = list(filter(lambda p: p.requires_grad, model.parameters()))\n",
    "    # for name, param in model.named_parameters():\n",
    "    #     if param.requires_grad:\n",
    "    #         print(name)\n",
    "    optimizer = optim.Adam(parameters, lr=lr)\n",
    "    # optimizer = optim.AdamW(parameters, lr=lr)\n",
    "    # optimizer = optim.SGD(parameters, lr=lr)\n",
    "\n",
    "    \n",
    "    \n",
    "    hyparam_info(emb_dim=embed_dim, loss_id=expID, ln_rate=lr, batch=batch_size, epc=epochs, ls_mrgn=loss_margin, trn_sz=train_data.shape[0], mdl_nm=model.modelName)\n",
    "\n",
    "    print(\"Training Start\")\n",
    "    all_loses = train(model, criterion, optimizer, train_loader, num_epochs=epochs, dev=device)\n",
    "    df_loss = pd.DataFrame({'Loss': all_loses})\n",
    "    df_loss.to_csv(f'losses/losses_{expID}.csv')\n",
    "\n",
    "\n",
    "\n",
    "    print(\"\\nExtract Features:\")\n",
    "    query_features, query_labels = predict(model=model, dataloader=val_loader_que, dev=device, isQuery=True)\n",
    "    reference_features, reference_labels = predict(model = model, dataloader=val_loader_ref, dev=device, isQuery=False) \n",
    "    \n",
    "\n",
    "\n",
    "    print(\"Compute Scores:\")\n",
    "    # r1 =  calculate_scores(query_features, reference_features, query_labels, reference_labels, step_size=1000, ranks=[1, 5, 10])\n",
    "    r1 =  accuracy(query_features=query_features, reference_features=reference_features, query_labels=query_labels, topk=[1, 5, 10])\n",
    "    \n",
    "    save_losses(df=df_loss, \n",
    "                emb_dim=embed_dim, \n",
    "                loss_id=expID, \n",
    "                ln_rate=lr, \n",
    "                batch=batch_size, \n",
    "                epc=epochs, \n",
    "                ls_mrgn=loss_margin, \n",
    "                trn_sz=train_data.shape[0],\n",
    "                mdl_nm=model.modelName,\n",
    "                rslt=r1)\n",
    "\n",
    "\n",
    "    print(r1) \n",
    "        \n",
    "\n",
    "    torch.save(model, f'model_weights/{expID}/model_tr.pth')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fahimul/.conda/envs/CVGL/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/fahimul/.conda/envs/CVGL/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/fahimul/.conda/envs/CVGL/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fahimul/.conda/envs/CVGL/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/fahimul/.conda/envs/CVGL/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hyperparameter info:\n",
      "Exp ID: 6257958\n",
      "Embedded dimension: 1000\n",
      "Learning rate: 1e-05\n",
      "Batch Size: 64\n",
      "Loss Margin: 1\n",
      "Epoch: 100\n",
      "Training Size: 10658\n",
      "Model Name: CLIP\n",
      "\n",
      "\n",
      "Training Start\n",
      "\n",
      "Date: 2024-05-20 22:19:19.471950\n",
      "\n",
      "Epoch#0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [06:45<00:00,  2.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/100 Loss: 3.67783522605896\n",
      "Epoch#1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [06:48<00:00,  2.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2/100 Loss: 3.4610238075256348\n",
      "Epoch#2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [06:39<00:00,  2.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3/100 Loss: 3.390040874481201\n",
      "Epoch#3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [06:44<00:00,  2.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4/100 Loss: 3.353699207305908\n",
      "Epoch#4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [06:54<00:00,  2.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5/100 Loss: 3.3104639053344727\n",
      "Epoch#5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [06:45<00:00,  2.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6/100 Loss: 3.2868146896362305\n",
      "Epoch#6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [06:54<00:00,  2.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7/100 Loss: 3.261460065841675\n",
      "Epoch#7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [07:13<00:00,  2.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8/100 Loss: 3.2388217449188232\n",
      "Epoch#8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [07:05<00:00,  2.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9/100 Loss: 3.2311360836029053\n",
      "Epoch#9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [06:59<00:00,  2.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10/100 Loss: 3.208472728729248\n",
      "Epoch#10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [06:21<00:00,  2.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11/100 Loss: 3.1945183277130127\n",
      "Epoch#11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [06:58<00:00,  2.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12/100 Loss: 3.1947290897369385\n",
      "Epoch#12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [07:06<00:00,  2.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13/100 Loss: 3.1859302520751953\n",
      "Epoch#13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [07:01<00:00,  2.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14/100 Loss: 3.178889751434326\n",
      "Epoch#14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [06:53<00:00,  2.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15/100 Loss: 3.170306444168091\n",
      "Epoch#15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [06:53<00:00,  2.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16/100 Loss: 3.164330005645752\n",
      "Epoch#16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [07:14<00:00,  2.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17/100 Loss: 3.1545979976654053\n",
      "Epoch#17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [07:10<00:00,  2.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18/100 Loss: 3.146165609359741\n",
      "Epoch#18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [06:38<00:00,  2.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19/100 Loss: 3.1381149291992188\n",
      "Epoch#19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [07:12<00:00,  2.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20/100 Loss: 3.130805253982544\n",
      "Epoch#20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [07:12<00:00,  2.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21/100 Loss: 3.12326979637146\n",
      "Epoch#21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [07:08<00:00,  2.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22/100 Loss: 3.1190996170043945\n",
      "Epoch#22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [07:09<00:00,  2.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23/100 Loss: 3.1181888580322266\n",
      "Epoch#23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [06:28<00:00,  2.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24/100 Loss: 3.116948366165161\n",
      "Epoch#24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [07:06<00:00,  2.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25/100 Loss: 3.1094067096710205\n",
      "Epoch#25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [07:02<00:00,  2.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26/100 Loss: 3.1017422676086426\n",
      "Epoch#26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [07:26<00:00,  2.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27/100 Loss: 3.097783088684082\n",
      "Epoch#27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [06:38<00:00,  2.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28/100 Loss: 3.094224452972412\n",
      "Epoch#28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [06:51<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29/100 Loss: 3.089644193649292\n",
      "Epoch#29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [07:12<00:00,  2.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30/100 Loss: 3.084209442138672\n",
      "Epoch#30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [06:57<00:00,  2.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 31/100 Loss: 3.079519748687744\n",
      "Epoch#31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [06:49<00:00,  2.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 32/100 Loss: 3.0773210525512695\n",
      "Epoch#32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [07:16<00:00,  2.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 33/100 Loss: 3.0771524906158447\n",
      "Epoch#33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [07:16<00:00,  2.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 34/100 Loss: 3.0760586261749268\n",
      "Epoch#34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [07:11<00:00,  2.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 35/100 Loss: 3.0722129344940186\n",
      "Epoch#35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [07:45<00:00,  2.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 36/100 Loss: 3.068732261657715\n",
      "Epoch#36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [06:39<00:00,  2.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 37/100 Loss: 3.06258487701416\n",
      "Epoch#37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [07:08<00:00,  2.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 38/100 Loss: 3.058687210083008\n",
      "Epoch#38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [07:08<00:00,  2.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 39/100 Loss: 3.055567979812622\n",
      "Epoch#39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [06:29<00:00,  2.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40/100 Loss: 3.053041458129883\n",
      "Epoch#40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [07:02<00:00,  2.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 41/100 Loss: 3.052685260772705\n",
      "Epoch#41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [06:38<00:00,  2.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 42/100 Loss: 3.054924249649048\n",
      "Epoch#42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [07:07<00:00,  2.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 43/100 Loss: 3.0530338287353516\n",
      "Epoch#43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [07:12<00:00,  2.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 44/100 Loss: 3.0506651401519775\n",
      "Epoch#44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [07:12<00:00,  2.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 45/100 Loss: 3.0471460819244385\n",
      "Epoch#45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [07:08<00:00,  2.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 46/100 Loss: 3.042741060256958\n",
      "Epoch#46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [07:10<00:00,  2.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 47/100 Loss: 3.037795305252075\n",
      "Epoch#47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [06:58<00:00,  2.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 48/100 Loss: 3.0342514514923096\n",
      "Epoch#48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [06:41<00:00,  2.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 49/100 Loss: 3.0324153900146484\n",
      "Epoch#49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [07:03<00:00,  2.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 50/100 Loss: 3.0312507152557373\n",
      "Epoch#50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [07:04<00:00,  2.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 51/100 Loss: 3.031346082687378\n",
      "Epoch#51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [04:42<00:00,  1.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 52/100 Loss: 3.031572103500366\n",
      "Epoch#52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:57<00:00,  1.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 53/100 Loss: 3.0308678150177\n",
      "Epoch#53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:57<00:00,  1.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 54/100 Loss: 3.02876615524292\n",
      "Epoch#54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:56<00:00,  1.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 55/100 Loss: 3.028168201446533\n",
      "Epoch#55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:56<00:00,  1.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 56/100 Loss: 3.0268430709838867\n",
      "Epoch#56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:57<00:00,  1.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 57/100 Loss: 3.023682117462158\n",
      "Epoch#57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:56<00:00,  1.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 58/100 Loss: 3.0221352577209473\n",
      "Epoch#58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:57<00:00,  1.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 59/100 Loss: 3.01987886428833\n",
      "Epoch#59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:57<00:00,  1.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 60/100 Loss: 3.0188169479370117\n",
      "Epoch#60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:59<00:00,  1.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 61/100 Loss: 3.0181427001953125\n",
      "Epoch#61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:58<00:00,  1.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 62/100 Loss: 3.0171589851379395\n",
      "Epoch#62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:58<00:00,  1.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 63/100 Loss: 3.01503849029541\n",
      "Epoch#63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:57<00:00,  1.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 64/100 Loss: 3.0125269889831543\n",
      "Epoch#64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:57<00:00,  1.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 65/100 Loss: 3.011002779006958\n",
      "Epoch#65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:59<00:00,  1.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 66/100 Loss: 3.0106594562530518\n",
      "Epoch#66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:57<00:00,  1.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 67/100 Loss: 3.0104265213012695\n",
      "Epoch#67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:58<00:00,  1.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 68/100 Loss: 3.010394811630249\n",
      "Epoch#68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:59<00:00,  1.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 69/100 Loss: 3.0106945037841797\n",
      "Epoch#69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:57<00:00,  1.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 70/100 Loss: 3.011859893798828\n",
      "Epoch#70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:59<00:00,  1.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 71/100 Loss: 3.039456605911255\n",
      "Epoch#71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:58<00:00,  1.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 72/100 Loss: 3.0525519847869873\n",
      "Epoch#72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:58<00:00,  1.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 73/100 Loss: 3.032297372817993\n",
      "Epoch#73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:57<00:00,  1.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 74/100 Loss: 3.009859561920166\n",
      "Epoch#74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:57<00:00,  1.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 75/100 Loss: 3.0010905265808105\n",
      "Epoch#75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:58<00:00,  1.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 76/100 Loss: 2.997390031814575\n",
      "Epoch#76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:58<00:00,  1.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 77/100 Loss: 2.9954235553741455\n",
      "Epoch#77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:58<00:00,  1.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 78/100 Loss: 2.994933605194092\n",
      "Epoch#78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:58<00:00,  1.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 79/100 Loss: 2.99466609954834\n",
      "Epoch#79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:57<00:00,  1.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 80/100 Loss: 2.9944465160369873\n",
      "Epoch#80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:58<00:00,  1.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 81/100 Loss: 2.994993209838867\n",
      "Epoch#81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [04:01<00:00,  1.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 82/100 Loss: 2.9961740970611572\n",
      "Epoch#82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:57<00:00,  1.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 83/100 Loss: 2.9975948333740234\n",
      "Epoch#83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:58<00:00,  1.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 84/100 Loss: 2.999452590942383\n",
      "Epoch#84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:57<00:00,  1.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 85/100 Loss: 3.0016772747039795\n",
      "Epoch#85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:58<00:00,  1.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 86/100 Loss: 3.0031633377075195\n",
      "Epoch#86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:57<00:00,  1.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 87/100 Loss: 3.003349542617798\n",
      "Epoch#87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:58<00:00,  1.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 88/100 Loss: 3.0017383098602295\n",
      "Epoch#88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:57<00:00,  1.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 89/100 Loss: 2.999363422393799\n",
      "Epoch#89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:58<00:00,  1.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 90/100 Loss: 2.9977176189422607\n",
      "Epoch#90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:57<00:00,  1.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 91/100 Loss: 3.0091552734375\n",
      "Epoch#91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:58<00:00,  1.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 92/100 Loss: 3.0385544300079346\n",
      "Epoch#92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:58<00:00,  1.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 93/100 Loss: 3.0350849628448486\n",
      "Epoch#93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:57<00:00,  1.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 94/100 Loss: 3.0056509971618652\n",
      "Epoch#94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:58<00:00,  1.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 95/100 Loss: 2.9953083992004395\n",
      "Epoch#95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:58<00:00,  1.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 96/100 Loss: 2.9920146465301514\n",
      "Epoch#96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:58<00:00,  1.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 97/100 Loss: 2.9905757904052734\n",
      "Epoch#97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:57<00:00,  1.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 98/100 Loss: 2.989732503890991\n",
      "Epoch#98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:58<00:00,  1.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 99/100 Loss: 2.989344596862793\n",
      "Epoch#99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [03:58<00:00,  1.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100/100 Loss: 2.9894866943359375\n",
      "\n",
      "Date: 2024-05-21 07:31:15.466920\n",
      "\n",
      "\n",
      "Extract Features:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 556/556 [01:13<00:00,  7.59it/s]\n",
      "100%|██████████| 556/556 [04:37<00:00,  2.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute Scores:\n",
      "Percentage-top1:18.445345041089723, top5:25.450298322638748, top10:28.06484295845998, top1%:49.40898345153664, time:2.6157195568084717\n",
      "[18.44534504 25.45029832 28.06484296 49.40898345]\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "# from torch.cuda.amp import autocast\n",
    "import numpy as np\n",
    "from CVUSA_dataset import CVUSA_dataset_cropped, CVUSA_Dataset_Eval\n",
    "# from CVUSA_dataset import CVUSA_Dataset_Eval\n",
    "from custom_models import ResNet, VIT, CLIP_model\n",
    "from losses import Contrastive_loss, SoftTripletBiLoss, InfoNCE\n",
    "from train import train\n",
    "from eval import predict, accuracy, calculate_scores\n",
    "import torch.nn.functional as F\n",
    "import copy\n",
    "import math\n",
    "from pytorch_metric_learning import losses as LS\n",
    "from helper_func import get_rand_id, hyparam_info, save_losses\n",
    "from transformers import CLIPProcessor\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# data_path = '/media/fahimul/2B721C03261BDC8D/Research/datasets/CVUSA' #don't include the / at the end\n",
    "# data_path = '/home/fa947945/datasets/CVUSA_Cropped/CVUSA' #don't include the / at the end\n",
    "data_path = '/data/Research/Dataset/CVUSA_Cropped/CVUSA' #don't include the / at the end\n",
    "\n",
    "# train_data= pd.read_csv(f'{data_path}/splits/train-19zl.csv')\n",
    "train_data= pd.read_csv(f'{data_path}/splits/train-19zl_30.csv')\n",
    "val_data= pd.read_csv(f'{data_path}/splits/val-19zl.csv')\n",
    "\n",
    "# df_loss = pd.DataFrame(columns=['Loss'])\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    # transforms.Resize((224, 224)),\n",
    "    transforms.RandomCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "\n",
    "train_ds = CVUSA_dataset_cropped(df = train_data, path=data_path, transform=transform)\n",
    "val_que = CVUSA_Dataset_Eval(data_folder=data_path, split='train', img_type='query', transforms=transform)\n",
    "val_ref = CVUSA_Dataset_Eval(data_folder=data_path, split='train', img_type='reference', transforms=transform)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Device: {device}\")\n",
    "    embed_dim = 1000\n",
    "    lr = 0.00001\n",
    "    batch_size = 64\n",
    "    epochs = 100\n",
    "    expID = get_rand_id()\n",
    "    loss_margin = 1\n",
    "\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=False)\n",
    "    val_loader_que = DataLoader(val_que, batch_size=batch_size, shuffle=False)\n",
    "    val_loader_ref = DataLoader(val_ref, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # os.mkdir(f'model_weights/{expID}')\n",
    "\n",
    "    # model = ResNet(emb_dim=embed_dim).to(device)\n",
    "    # model_r = ResNet(emb_dim=embed_dim).to(device)\n",
    "    # model_q = ResNet(emb_dim=embed_dim).to(device)\n",
    "\n",
    "    # model = ResNet().to(device)\n",
    "    # model = VIT().to(device)\n",
    "    model = CLIP_model(embed_dim=embed_dim)\n",
    "    \n",
    "    # torch.save(model, f'model_weights/{expID}/model_st.pth')\n",
    "\n",
    "    # criterion = TripletLoss(margin=loss_margin)\n",
    "    # criterion = nn.TripletMarginLoss(margin=0.5)\n",
    "  \n",
    "    # criterion = SoftTripletBiLoss()\n",
    "\n",
    "    loss_fn = torch.nn.CrossEntropyLoss(label_smoothing=0.5)\n",
    "    criterion = InfoNCE(loss_function=loss_fn,\n",
    "                            device=device,\n",
    "                            )\n",
    "\n",
    "\n",
    "\n",
    "    parameters = list(filter(lambda p: p.requires_grad, model.parameters()))\n",
    "    # for name, param in model.named_parameters():\n",
    "    #     if param.requires_grad:\n",
    "    #         print(name)\n",
    "    optimizer = optim.Adam(parameters, lr=lr)\n",
    "    # optimizer = optim.AdamW(parameters, lr=lr)\n",
    "    # optimizer = optim.SGD(parameters, lr=lr)\n",
    "\n",
    "    \n",
    "    \n",
    "    hyparam_info(emb_dim=embed_dim, loss_id=expID, ln_rate=lr, batch=batch_size, epc=epochs, ls_mrgn=loss_margin, trn_sz=train_data.shape[0], mdl_nm=model.modelName)\n",
    "\n",
    "    print(\"Training Start\")\n",
    "    all_loses = train(model, criterion, optimizer, train_loader, num_epochs=epochs, dev=device)\n",
    "    df_loss = pd.DataFrame({'Loss': all_loses})\n",
    "    df_loss.to_csv(f'losses/losses_{expID}.csv')\n",
    "\n",
    "\n",
    "\n",
    "    print(\"\\nExtract Features:\")\n",
    "    query_features, query_labels = predict(model=model, dataloader=val_loader_que, dev=device, isQuery=True)\n",
    "    reference_features, reference_labels = predict(model = model, dataloader=val_loader_ref, dev=device, isQuery=False) \n",
    "    \n",
    "\n",
    "\n",
    "    print(\"Compute Scores:\")\n",
    "    # r1 =  calculate_scores(query_features, reference_features, query_labels, reference_labels, step_size=1000, ranks=[1, 5, 10])\n",
    "    r1 =  accuracy(query_features=query_features, reference_features=reference_features, query_labels=query_labels, topk=[1, 5, 10])\n",
    "    \n",
    "    save_losses(df=df_loss, \n",
    "                emb_dim=embed_dim, \n",
    "                loss_id=expID, \n",
    "                ln_rate=lr, \n",
    "                batch=batch_size, \n",
    "                epc=epochs, \n",
    "                ls_mrgn=loss_margin, \n",
    "                trn_sz=train_data.shape[0],\n",
    "                mdl_nm=model.modelName,\n",
    "                rslt=r1)\n",
    "\n",
    "\n",
    "    print(r1) \n",
    "        \n",
    "\n",
    "    # torch.save(model, f'model_weights/{expID}/model_tr.pth')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
